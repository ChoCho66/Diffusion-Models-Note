% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
]{article}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
  \setmainfont[]{Latin Modern Roman}
  \setmathfont[]{Latin Modern Math}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{5}
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi


\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
% definitions for citeproc citations
\NewDocumentCommand\citeproctext{}{}
\NewDocumentCommand\citeproc{mm}{%
  \begingroup\def\citeproctext{#2}\cite{#1}\endgroup}
\makeatletter
 % allow citations to break across lines
 \let\@cite@ofmt\@firstofone
 % avoid brackets around text for \cite:
 \def\@biblabel#1{}
 \def\@cite#1#2{{#1\if@tempswa , #2\fi}}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-indent, #2 entry-spacing
 {\begin{list}{}{%
  \setlength{\itemindent}{0pt}
  \setlength{\leftmargin}{0pt}
  \setlength{\parsep}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
   \setlength{\leftmargin}{\cslhangindent}
   \setlength{\itemindent}{-1\cslhangindent}
  \fi
  % set entry spacing
  \setlength{\itemsep}{#2\baselineskip}}}
 {\end{list}}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{\hfill\break\parbox[t]{\linewidth}{\strut\ignorespaces#1\strut}}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\usepackage{xeCJK}
\usepackage{fontspec}
\setCJKmonofont{STFangsong}
\usepackage{arxiv}
\usepackage{orcidlink}
\usepackage{amsmath}
\usepackage[T1]{fontenc}
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\usepackage{amsthm}
\theoremstyle{remark}
\AtBeginDocument{\renewcommand*{\proofname}{Proof}}
\newtheorem*{remark}{Remark}
\newtheorem*{solution}{Solution}
\newtheorem{refremark}{Remark}[section]
\newtheorem{refsolution}{Solution}[section]
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\makeatletter
\@ifpackageloaded{algorithm}{}{\usepackage{algorithm}}
\makeatother
\makeatletter
\@ifpackageloaded{algpseudocode}{}{\usepackage{algpseudocode}}
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage{bookmark}

\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Diffusion Models Note},
  pdfauthor={ChoCho},
  pdfkeywords={Diffusion Models},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}

\newcommand{\runninghead}{A Preprint }
\renewcommand{\runninghead}{A Preprint }
\title{Diffusion Models Note}
\def\asep{\\\\\\ } % default: all authors on same column
\author{\textbf{ChoCho}\\Mathematics\\National Central
University\\Taoyuan City
320317\\\href{mailto:kycho@math.ncu.edu.tw}{kycho@math.ncu.edu.tw}}
\date{}
\begin{document}
\maketitle
\begin{abstract}
The purpose of this survey is to introduce the diffusion model. We will
first introduce the basic concepts of DDPM, and then introduce some
developments based on DDPM, including DDIM and the condition diffusion
model. We will be writing using symbols customary to the mathematics
department.
\end{abstract}
{\bfseries \emph Keywords}
\def\sep{\textbullet\ }

Diffusion Models


\renewcommand{\Return}{\State \textbf{return}~}
\newcommand{\Print}{\State \textbf{print}~}
\newcommand{\Break}{\State \textbf{break}}
\newcommand{\Continue}{\State \textbf{continue}}
\newcommand{\True}{\textbf{true}}
\newcommand{\False}{\textbf{false}}
\renewcommand{\And}{\textbf{and}~}
\newcommand{\Or}{\textbf{or}~}
\renewcommand{\Not}{\textbf{not}~}
\newcommand{\To}{\textbf{to}~}
\newcommand{\DownTo}{\textbf{downto}~}

\floatname{algorithm}{Algorithm}

\section{Introduction}\label{introduction}

\textbf{Diffusion Probabilistic Models (DPM, or Diffusion Models)} were
first proposed by Sohl-Dickstein et al. (2015). We will focus on the
DDPM (Denoising Diffusion Probabilistic Models) (Ho, Jain, and Abbeel
(2020)). We will also introduce some developments based on DDPM:
including DDIM (Denoising Diffusion Implicit Models)
(Section~\ref{sec-DDIM}) and the condition diffusion model
(Section~\ref{sec-cdm}).

The history of generative AI is rich and multifaceted, dating back
several decades. Initially, generative models were relatively
simplistic, but advancements over time have led to the development of
more sophisticated techniques. One of the earliest breakthroughs in this
field was the introduction of the Variational Autoencoder (VAE) (Kingma
and Welling (2022)). VAEs employ a probabilistic approach to model the
distribution of data, allowing for the generation of new, similar data
points by sampling from this distribution. Following VAEs, Generative
Adversarial Networks (GANs) (Goodfellow et al. (2014)) revolutionized
generative AI by using a game-theoretic approach, where two neural
networks---the generator and the discriminator---compete in a zero-sum
game, resulting in the creation of highly realistic data.

Diffusion models are a newer addition to this landscape and have shown
remarkable promise. These models work by simulating the diffusion
process, wherein data points are progressively transformed from a simple
distribution (like Gaussian noise) to a complex data distribution.
Notable types of diffusion models include Denoising Diffusion
Probabilistic Models (DDPMs) and Noise-Conditional Score Networks
(NCSNs). DDPMs iteratively refine noisy data points until they resemble
the target distribution, whereas NCSNs use score matching to model the
gradient of the data distribution, which guides the generation process.

Recent developments in diffusion models have focused on enhancing their
efficiency and quality. Innovations such as improved noise scheduling,
hybrid architectures combining features from VAEs and GANs, and
advancements in training techniques have all contributed to the rapid
evolution of diffusion models. These advancements have enabled diffusion
models to generate data with unprecedented fidelity and have opened new
avenues for their application across various domains, including image
synthesis, natural language processing, and beyond.

In summary, diffusion models have emerged as a powerful tool within the
generative AI toolkit. Their ongoing development promises to further
push the boundaries of what is possible in data generation, offering
exciting possibilities for both research and practical applications.

Next, we introduce the basic concepts of DDPM.

\section{Background}\label{background}

The diffusion model consists of two main parts:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Adding Noise (Forward Process):} We gradually introduce
  independent noise to the starting image until it becomes pure noise.
\item
  \textbf{Denoising (Backward Process):} Beginning with pure noise, we
  use the current image to estimate what the previous image looked like.
  Repeating this process step by step, the final output image is our
  generated picture.
\end{enumerate}

TODO: 補圖

We use mathematical formulas to describe the above statement. Given
\(T\in \mathbb N.\) Fix constants \(\alpha_t,\beta_t\in (0.001,0.999)\)
for \(t=1,2,\cdots,T\) such that \(\alpha_t+\beta_t=1.\) We set the
following random vectors of \(\mathbb R^n\) (note that here we only have
random vectors and not probability measures):

\begin{itemize}
\tightlist
\item
  \(X_0\): The initial image.
\item
  \(\mathcal{E}_t,\, t=1,2,\cdots,T\): The noise added in step \(t\).
\item
  \(X_t = \sqrt{\alpha_{t}}X_{t-1} + \sqrt{\beta_t}\mathcal{E}_t,\, t=1,2,\cdots,T\):
  The image in step \(t.\)
\end{itemize}

To have the concepts of \textbf{independence} and \textbf{noise}, we
need to have probability measures. In the following text, we use
lowercase \(q(x)\) to denote the density of a probability measure
\(\mathbf{Q}\) corresponding to the random variable \(X.\) Others (e.g.,
\(q(x_t),p_{\theta}(x_t)\)) are the same (\(p_{\theta}\) corresponds to
\(\mathbf{P}_{\theta}\)). We also use \(q(x_{0:t})\) to denote the
density of \((X_0,X_1,\cdots,X_t):=X_{0:t}\) for the probability measure
\(\mathbf{Q}.\) Others are the same.

Suppose \(q_{\text{want}}(x_0)\) is the density of \(X_0\) we want to
pursue. We do not know what \(q_{\text{want}}(x_0)\) is. We only have
some eligible images (discrete data) with mass function
\({\color{blue}{q(x_0)}}.\) When this discrete data large,
\(q(x_0)\approx q_{\text{want}}(x_0)\) in some sense of distribution.
\textbf{Our goal} is to find a density \(p(x_0)\) of \(X_0\) such that
\(p(x_0)\approx q_{\text{want}}(x_0)\) in some sense of distribution.

\subsection{Forward process}\label{forward-process}

TODO: Notation

In the forward process, we add noise independently to the image. Note
that adding noise independently is equivalent to the Markov property
(see Section~\ref{sec-markov-equivalent}). We define the \textbf{forward
process} \(\bigl( \lbrace X_0,\cdots,X_T\rbrace,\mathbf{Q} \bigr)\) as a
Markov chain with

\begin{itemize}
\tightlist
\item
  the initial density \(q(x_0),\) and
\item
  the transition density \[
  \begin{aligned}
    q(x_t\vert x_{t-1}) = \mathcal{N} (\sqrt{\alpha_t}x_{t-1},\beta_t \mathbf{I}).
  \end{aligned}
  \]
\end{itemize}

By the Markov property, the joint density of
\((X_T, X_{T-1},\cdots, X_1, X_0)\) for the forward process (or we say
under \(\mathbf{Q}\)) is \[
\begin{aligned}
  q(x_{T:0}) = q(x_T\vert x_{T-1}) \cdot q(x_{T-1}\vert x_{T-2}) \cdots q(x_{1}\vert x_0) \cdot q(x_0).
\end{aligned}
\] Recall that
\(X_t = \sqrt{\alpha_{t}}X_{t-1} + \sqrt{\beta_t}\mathcal{E}_t.\) Then
under \(\mathbf{Q},\)
\(\underline{\mathcal{E}_t\sim \mathcal{N}(\mathbf{0},\mathbf{I})}\) and
\[
\begin{aligned}
  \underline{X_0,\mathcal{E}_1,\mathcal{E}_2,\cdots,\mathcal{E}_t\text{ are independent}}
\end{aligned}
\] (see TODO: appendix). Define a random vector
\(\overline{\mathcal{E}}_t\) by
\begin{equation}\phantomsection\label{eq-Xt-X0-Et}{
\begin{aligned}
  X_t = \sqrt{\overline{\alpha}_t}X_0 + \sqrt{1-\overline{\alpha}_t} \cdot \overline{\mathcal{E}}_t,
\end{aligned}
}\end{equation} where
\(\overline{\alpha}_t = \alpha_t\cdot \alpha_{t-1}\cdots \alpha_1.\)
Then under \(\mathbf{Q},\)
\(\underline{\overline{\mathcal{E}}_t\perp X_0}\) and
\(\underline{\overline{\mathcal{E}}_t\sim \mathcal{N}(\mathbf{0},\mathbf{I})}.\)
This implies that \(X_T\) converges in distribution to
\(\mathcal{N}(\mathbf{0},\mathbf{I})\) under \(\mathbf{Q}\) for \(T\)
large.

Equation~\ref{eq-Xt-X0-Et} is a important relation between \(X_t\) and
\(X_0\) and the noise \(\overline{\mathcal{E}}_t.\) For example, if we
have an estimator of \(\overline{\mathcal{E}}_t,\) say
\(\widehat{\overline{\mathcal{E}_t}},\) then by this relationship, we
have an estimator
\(\widehat{X}_0 = \widehat{X}_0\Bigl(X_t,\widehat{\overline{\mathcal{E}_t}}\Bigr)\)
of \(X_0\) satisfies the following:
\begin{equation}\phantomsection\label{eq-estimator-X0}{
\begin{aligned}
  X_t = \sqrt{\overline{\alpha}_t} \widehat{X}_0 + \sqrt{1-\overline{\alpha}_t} \cdot \widehat{\overline{\mathcal{E}_t}}.
\end{aligned}
}\end{equation} We will use this relationship when we reparameterize our
model.

\subsection{Backward process}\label{backward-process}

In the backward process, we remove the noise according to the current
image. This can also be described by the Markov chain. Ideally we define
the \textbf{backward process}
\(\bigl( \lbrace X_T,X_{T-1},\cdots,X_1,X_0 \rbrace, \mathbf{P} \bigr)\)
as a Markov chain with the initial distribution
\(p(x_T) = \mathcal{N}(\mathbf{0},\mathbf{I})\) and the transition
density \(p(x_{t-1}\vert x_t)=q(x_{t-1}\vert x_t).\) In this assumption,
we have \(p(x_0)\approx q(x_0)\) in some sense of distribution (see
TODO: appendix). We may sample \(x_0\sim p(x_0)\) by the following:

\begin{itemize}
\tightlist
\item
  Sample \(x_T\sim \mathcal{N}(\mathbf{0},\mathbf{I}).\)
\item
  Sample \(x_{t-1}\sim q(x_{t-1}\vert x_t)\) inductively for
  \(t=T,T-1,\cdots,1.\)
\end{itemize}

However, there is a problem with the sampling above. Although from the
properties of conditional density, we have \[
\begin{aligned}
  q(x_{t-1}\vert x_t) = \frac{q(x_{t-1})}{q(x_t)} \cdot q(x_t\vert x_{t-1}).
\end{aligned}
\] It's not easy to use this formula to sample
\(x_{t-1}\sim q(x_{t-1}\vert x_t)\) through code since the expression of
\(q(x_{t-1})/q(x_t)\) may be complicated. The way to solve this problem
is that we assume there is another probability measure
\(\mathbf{P}_{\theta}\) (this is our model, which can be sampled through
code). There are several methods (SDE or just Taylor's theory, see TODO:
appendix) to show that we can approximate \(q(x_{t-1}\vert x_t)\) with a
normal. Hence, we construct \(\mathbf{P}_{\theta}\) such that \[
\begin{aligned}
  p_{\theta}(x_{t-1}\vert x_t) = \mathcal{N}\bigl(x_{t-1}; \mu_{\theta}(x_t,t),\Sigma_{\theta}(x_t,t)\bigr),
\end{aligned}
\] where \(\mu_{\theta},\, \Sigma_{\theta}\) is what we need to give. A
way to construct \(\mathbf{P}_{\theta}\) is that we consider
\(\bigl( \lbrace X_T,X_{T-1},\cdots, X_1,X_0\rbrace,\mathbf{P}_{\theta} \bigr)\)
is a Markov chain with

\begin{itemize}
\tightlist
\item
  the initial density
  \(p_{\theta}(x_T) = \mathcal{N}(\mathbf{0},\mathbf{I})\) and
\item
  the transition density \[
  \begin{aligned}
    \color{blue}{p_{\theta}(x_{t-1}\vert x_t) = \mathcal{N}\bigl(x_{t-1}; \mu_{\theta}(x_t,t),\Sigma_{\theta}(x_t,t)\bigr).}
  \end{aligned}
  \]
\end{itemize}

The joint density of \(X_{0:T}\) (under \(\mathbf{P}_{\theta}\)) is, by
the Markov property, \[
\begin{aligned}
  p_{\theta}(x_{0:T}) = p_{\theta}(x_0 \vert x_1) \cdot p_{\theta}(x_1\vert x_2) \cdots p_{\theta}(x_{T-1}\vert x_T) \cdot p(x_T).
\end{aligned}
\] We can sample \(x_0\sim p_{\theta}(x_0)\) by the following:

\begin{itemize}
\tightlist
\item
  Sample \(x_T\sim \mathcal{N}(\mathbf{0},\mathbf{I}).\)
\item
  Sample \(x_{t-1}\sim p_{\theta}(x_{t-1}\vert x_t)\) inductively for
  \(t=T,T-1,\cdots,1.\)
\end{itemize}

Now \textbf{our goal} becomes to optimize \(\theta\) such that
\(p_{\theta}(x_0)\approx q(x_0)\) in some sense. A common way to measure
the difference between \(p_{\theta}(x_0)\) and \(q(x_0)\) is the
\href{https://en.wikipedia.org/wiki/Kullback–Leibler_divergence}{KL-divergence}
\[
\begin{aligned}
  D_{\mathtt{KL}} \bigl( q(x_0) \Vert p_{\theta}(x_0) \bigr) 
  = \int_{x_0\in \mathbb R^n} q(x_0) \log \frac{q(x_0)}{p_{\theta}(x_0)} \mathrm{d}x_0.
\end{aligned}
\] By the definition of the KL-divergence, \[
\begin{aligned}
\mu_{\theta}^*, \Sigma_{\theta}^* 
&= \arg \min_{\mu_{\theta},\Sigma_{\theta}} D_{\mathtt{KL}} \bigl( q(x_0) \big\Vert p_{\theta}(x_0) \bigr) \cr 
&= \arg \min_{\mu_\theta,\Sigma_\theta} \biggl( -\int q(x_0) \log \Bigl( \frac{p_{\theta}(x_0)}{q(x_0)} \Bigr) \mathrm{d}x_0 \biggr) \cr
&= \arg \min_{\mu_{\theta},\Sigma_{\theta}} \biggl( \underbrace{-\int q(x_0) \log p_{\theta}(x_0) \mathrm{d}x_0}_{\color{blue}{\mathbb E_{X_0\sim q(x_0)}[-\log p_{\theta}(X_0)]}} \biggr).
\end{aligned}
\] Through the
\href{https://en.wikipedia.org/wiki/Evidence_lower_bound}{evidence lower
bound(ELBO)}, \[
\begin{aligned}
  {\color{blue}{\mathbb E_{X_0\sim q(x_0)}[-\log p_{\theta}(X_0)]}} \leq 
  \mathbb E_{X_{0:T}\sim q(x_{0:T})} \Bigl[ -\log \frac{p_{\theta}(X_{0:T})}{q(X_{1:T}\vert X_0)} \Bigr]:= L.
\end{aligned}
\] Our goal becomes to minimize \(L.\) We separate \(L\) into three
parts (for details, see TODO: appendix):
\begin{equation}\phantomsection\label{eq-decom-L}{
\begin{aligned}
  L 
  &= \underbrace{\mathbb E_{X_0\sim q(x_0)} \biggl[ D_{\mathtt{KL}} \Bigl( \underline{q(x_T \vert x_0)} \big\Vert \underline{p(x_T)} \Bigr) \Big\vert_{x_0=X_0} \biggr]}_{L_T} \cr 
  & \qquad + \sum_{t=2}^T 
  \underbrace{\mathbb E_{X_0,X_t\sim q(x_0,x_{t})} \biggl[ 
    D_{\mathtt{KL}} \Bigl( 
            {\underline{\color{red}{q(x_{t-1} \vert x_t,x_0)}}}
            \big\Vert 
            \underline{\color{blue}{p_{\theta}(x_{t-1}\vert x_t)} }
            \Bigr)\Big \vert_{x_0,x_t=X_0,X_t} 
    \biggr]}_{L_{t-1}}  \cr 
    & \qquad \qquad + \underbrace{\mathbb E_{X_0,X_1\sim q(x_0,x_1)} \biggl[ 
      -\log {\color{blue}{p_{\theta}(x_0 \vert x_1)}} \Big\vert_{x_0,x_1=X_0,X_1}
      \biggr]}_{L_0}.
\end{aligned}
}\end{equation}

\begin{itemize}
\item
  The first term \(L_T\) controls how similar is the last image of the
  forward process to the pure noise. \(L_T\) can be calculated directly
  since both \(q(x_T \vert x_0),\, p(x_T)\) are normal. The value is \[
  \begin{aligned}
    L_T = \frac{1}{2} \biggl( \log (1-\overline{\alpha}_T) + n \Bigl( \frac{1}{1-\overline{\alpha}_T} - 1 \Bigr) + \frac{\overline{\alpha}_T}{1-\overline{\alpha}_T} \mathbb E_{X_0\sim q(x_0)}\bigl[ \left\lVert X_0 \right\rVert^2 \bigr] \biggr).
  \end{aligned}
  \] It is clear that \(\lim_{T\rightarrow\infty} L_t = 0.\) From the
  above formula, depending only on the \(L^2\)-norm of \(X_0,\) \(L_T\)
  can be smaller if we shift \(X_0\) by its mean. We may see the case
  \(n=1.\) TODO: 圖 For the question of how to choose the size of \(T\),
  see TODO: ref.
\item
  The second term \(L_{t-1},\) \(t=2,\cdots,T,\) is the most important
  since it determines how to choose \(\mu_{\theta},\Sigma_{\theta}.\)
  This term controls the similarity of \(X_{t-1}\) in the forward and
  backward process. By Bayes' rule and after a long calculation (see
  TODO: appendix), \[
  \begin{aligned}
    {\color{red}{q(x_{t-1} \vert x_t,x_0)}} = \mathcal{N}\bigl( x_{t-1}; \mu_{t}(x_t,x_0),\Sigma_t \bigr),
    \quad t = 2,\cdots,T,
  \end{aligned}
  \] where \begin{equation}\phantomsection\label{eq-mu_t}{
  \begin{aligned}
    \mu_{t}(x_t,x_0)  
    = \frac{\sqrt{\alpha_t}(1-\overline{\alpha}_{t-1})}{1-\overline{\alpha}_t}x_t + \frac{\sqrt{\overline{\alpha}_{t-1}}\beta_t}{1-\overline{\alpha}_t}x_0 ,
    \quad
    \Sigma_t = \frac{1-\overline{\alpha}_{t-1}}{1-\overline{\alpha}_t}\beta_t \mathbf{I}.
  \end{aligned}
  }\end{equation}

  \subsubsection{\texorpdfstring{To determine \(\Sigma_{\theta}\) for
  \(t\geq 2\)}{To determine \textbackslash Sigma\_\{\textbackslash theta\} for t\textbackslash geq 2}}\label{to-determine-sigma_theta-for-tgeq-2}

  Since both
  \(q(x_{t-1}\vert x_t, x_0),\, p_{\theta}(x_{t-1}\vert x_t)\) are
  normal, it is natural to choose
  \begin{equation}\phantomsection\label{eq-Sig_the_indep_x}{
  \begin{aligned}
    \Sigma_{\theta}(x,t) =
    \Sigma_t &= \frac{1-\overline{\alpha}_{t-1}}{1-\overline{\alpha}_t}\beta_t \mathbf{I}
    := {\color{blue}{\sigma_t^2}} \mathbf{I}.
  \end{aligned}
  }\end{equation}

  \subsubsection{\texorpdfstring{To determine \(\mu_{\theta}\) for
  \(t\geq 2\)}{To determine \textbackslash mu\_\{\textbackslash theta\} for t\textbackslash geq 2}}\label{to-determine-mu_theta-for-tgeq-2}

  By the choice of \(\Sigma_{\theta},\) we have \[
  \begin{aligned}
    L_{t-1} 
    &= \mathbb E_{X_0,X_t\sim q(x_0,x_t)} \Bigl[ \frac{1}{2\sigma_t^2} \bigl\lVert \mu_t(X_t,X_0) - \mu_{\theta}(X_t,t) \bigr\rVert^2 \Bigr] \cr 
    &= \mathbb E_{\substack{X_0\sim q(x_0), \overline{\mathcal{E}}_t\sim \mathcal{N}(\mathbf{0},\mathbf{I})\\ X_0,\overline{\mathcal{E}}_t \text{ are independent} \\X_t=\sqrt{\overline{\alpha}_t}X_0+\sqrt{1-\overline{\alpha}_t}\cdot \overline{\mathcal{E}}_t}} \Bigl[ \frac{1}{2\sigma_t^2} \bigl\lVert \mu_t(X_t,X_0) - \mu_{\theta}(X_t,t) \bigr\rVert^2 \Bigr].
  \end{aligned}
  \] Then we reparametrize \(\mu_{\theta}\) by
  \begin{equation}\phantomsection\label{eq-mu_the_mu_t}{
  \begin{aligned}
    \mu_{\theta}(X_t,t)=\mu_t\bigl(X_t, \widehat{X}_0\bigr),
  \end{aligned}
  }\end{equation} where \(\widehat{X}_0=\widehat{X}_0(X_t)\) is the
  estimate of \(X_0\) via our model by giving \(X_t\) (we will give the
  details of \(\widehat{X}_0\) later in Equation~\ref{eq-Net_asssume1}).
  With this parametrization and by the expression of \(\mu_{t}\) in
  Equation~\ref{eq-mu_t}, we have
  \begin{equation}\phantomsection\label{eq-Net_asssume0}{
  \begin{aligned}
    \bigl\lVert \mu_t(X_t,X_0) - \mu_{\theta}(X_t,t)  \bigr\rVert 
    = \frac{\sqrt{\overline{\alpha}_{t-1}}\beta_t}{1-\overline{\alpha}_t}\big\lVert X_0 - \widehat{X}_0(X_t) \big\rVert.
  \end{aligned}
  }\end{equation} Let
  \(\mathtt{Net}_{\theta}:\mathbb R^n\times \lbrace 1,2,\cdots,T\rbrace\longrightarrow \mathbb R^n\)
  be our neural network (with parameters \(\theta\)) we need to train.
  We can choose \(\mathtt{Net}_{\theta}\) to predict \(X_0,\) or
  \(\overline{\mathcal{E}}_t\) or the velocity \(V_t\) (see Hang et al.
  (2023)). DDPM chooses to predict the noise
  \(\overline{\mathcal{E}}_t.\) Then by Equation~\ref{eq-estimator-X0},
  we have the following relation
  \begin{equation}\phantomsection\label{eq-Net_asssume1}{
  \begin{aligned}
    X_t = \sqrt{\overline{\alpha}_t} \cdot \widehat{X}_0(X_t) + \sqrt{1-\overline{\alpha}_t} \cdot \mathtt{Net}_{\theta}(X_t,t).
  \end{aligned}
  }\end{equation} Note that
  \(\widehat{X}_0 = \widehat{X}_0(X_t)=\widehat{X}_0(X_t,\theta).\)
  Hence, we have \[
  \begin{aligned}
    L_{t-1} = \mathbb E_{\substack{X_0\sim q(x_0), \overline{\mathcal{E}}_t\sim \mathcal{N}(\mathbf{0},\mathbf{I})\\ X_0,\overline{\mathcal{E}}_t \text{ are independent} \\ X_t=\sqrt{\overline{\alpha}_t}X_0+\sqrt{1-\overline{\alpha}_t}\cdot \overline{\mathcal{E}}_t}} \biggl( \frac{\beta_t^2}{2\sigma_t^2\alpha_t(1-\overline{\alpha}_t)} \Big\lVert \overline{\mathcal{E}}_t - \mathtt{Net}_{\theta}(X_t,t) \Big\rVert^2 \biggr).
  \end{aligned}
  \]
\item
  For the third term \(L_0.\) Recall that we assume
  \(p_{\theta}(x_0 \vert x_1) = \mathcal{N}\bigl(x_0; \mu_{\theta}(x_1,1), \Sigma_{\theta}(x_1,1) \bigr).\)
  For convience (see Equation~\ref{eq-Sig_the_indep_x}), we choose
  \(\Sigma_{\theta}(x_1,1)\) to be a constant matrix indepdent of
  \(\theta\) and \(x_1,\) e.g., \[
  \begin{aligned}
    \Sigma_{\theta}(x_1,1) = \beta_1 \mathbf{I}:={\color{blue}{\sigma_1^2}} \mathbf{I}.
  \end{aligned}
  \] Note that \[
  \begin{aligned}
    -\log p_{\theta} (x_0\vert x_1) = \frac{1}{2\beta_1} \big\lVert x_0 - \mu_{\theta}(x_1,1) \big\rVert^2 + \mathtt{const} ,
  \end{aligned}
  \] where \(\mathtt{const}\) is some constant independent of
  \((x_0,x_1,\theta).\) Here we also reparametrize \(\mu_{\theta}\) by
  Equation~\ref{eq-mu_the_mu_t} for \(t=1\) with
  \(\overline{\alpha}_0:=1.\) In this setting, \[
  \begin{aligned}
    \mu_\theta(X_1,1)=\mu_1(X_1,\widehat{X}_0(X_1))=\widehat{X}_0(X_1).
  \end{aligned}
  \] To maximize \[
  \begin{aligned}
    L_0
    = \mathbb E_{X_0,X_1\sim q(x_0,x_1)} \biggl[ 
      -\log {\color{blue}{p_{\theta}(x_0 \vert x_1)}} \Big\vert_{x_0,x_1=X_0,X_1}
      \biggr]
  \end{aligned}
  \] is equivalent to maximize \[
  \begin{aligned}
    L_0'=\mathbb E_{X_0,X_1\sim q(x_0,x_1)} \biggl[
      \frac{1}{2\beta_1} \big\lVert X_0 - \widehat{X}_0(X_1) \big\rVert^2
      \biggr].
  \end{aligned}
  \] Hence, if we use the same assumption from
  Equation~\ref{eq-Net_asssume1}, our goal is to minimize \[
  \begin{aligned}
    L_0' &=  \mathbb E_{X_0,X_1\sim q(x_0,x_1)} \biggl[
      \frac{1-\alpha_1}{2\beta_1 \alpha_1} 
      \big\lVert X_0 - \widehat{X}_0(X_1)  
      \big\rVert^2
      \biggr]  \cr
      &=
      \mathbb E_{\substack{X_0\sim q(x_0), \overline{\mathcal{E}}_t\sim \mathcal{N}(\mathbf{0},\mathbf{I})\\ X_0,\overline{\mathcal{E}}_t \text{ are independent} \\ X_t=\sqrt{\overline{\alpha}_t}X_0+\sqrt{1-\overline{\alpha}_t}\cdot \overline{\mathcal{E}}_t}} \biggl( \frac{\beta_t^2}{2\sigma_t^2\alpha_t(1-\overline{\alpha}_t)} \Big\lVert \overline{\mathcal{E}}_t - \mathtt{Net}_{\theta}(X_t,t) \Big\rVert^2 \biggr)
  \end{aligned}
  \] with \(t=1.\)
\end{itemize}

\subsection{Training and Sampling}\label{training-and-sampling}

Note that we will minimize \(\mathbb E_{X\sim q(x)}[f_{\theta}(X)]\) by
\textbf{repeating} the following:

\begin{itemize}
\tightlist
\item
  Sampling \(x\sim q(x)\) and then
\item
  minimizing \(f_{\theta}(x)\) by taking gradient descent on \(\theta.\)
\end{itemize}

Recall that for \(t = 2,3,\cdots,T,\) \[
\begin{aligned}
  L_{t-1} = \mathbb E_{\substack{X_0\sim q(x_0), \overline{\mathcal{E}}_t\sim \mathcal{N}(\mathbf{0},\mathbf{I})\\ X_0,\overline{\mathcal{E}}_t \text{ are independent} \\ X_t=\sqrt{\overline{\alpha}_t}X_0+\sqrt{1-\overline{\alpha}_t}\cdot \overline{\mathcal{E}}_t}} \biggl( \frac{\beta_t^2}{2\sigma_t^2\alpha_t(1-\overline{\alpha}_t)} \Big\lVert \overline{\mathcal{E}}_t - \mathtt{Net}_{\theta}(X_t,t) \Big\rVert^2 \biggr).
\end{aligned}
\] DDPM chooses a simple version that minimizes
\(L_{t-1}^{\text{simple}},\) ignoring the weights in the expectation: \[
\begin{aligned}
  L_{t-1}^{\text{simple}} = \mathbb E_{\substack{X_0\sim q(x_0), \overline{\mathcal{E}}_t\sim \mathcal{N}(\mathbf{0},\mathbf{I})\\ X_0,\overline{\mathcal{E}}_t \text{ are independent} \\ X_t=\sqrt{\overline{\alpha}_t}X_0+\sqrt{1-\overline{\alpha}_t}\cdot \overline{\mathcal{E}}_t}} \biggl(  \Big\lVert \overline{\mathcal{E}}_t - \mathtt{Net}_{\theta}(X_t,t) \Big\rVert^2 \biggr).
\end{aligned}
\] \(L_0\) is the same. Therefore, our training algorithm is as follows:

\begin{algorithm}[H]
\caption{Training (DDPM)}
\label{alg-test-text-style}
\begin{algorithmic}[1]
\Repeat\State $t\sim \text{Uniform}(\lbrace 1,\cdots,T \rbrace)$\Comment{ Sample random step}\State $x_0\sim q(x_0)$\Comment{ Sample random initial image}\State $\overline{\varepsilon}_t\sim \mathcal{N}(\mathbf{0},\mathbf{I})$\Comment{ Sample random noise}\State $x_t = \sqrt{\overline{\alpha}_t}x_0 + \sqrt{1-\overline{\alpha}_t}\cdot \overline{\varepsilon}_t$\State Take gradient descent step on $\Bigl\lVert \overline{\varepsilon}_t - \mathtt{Net}_{\theta}(x_t,t) \Bigr\rVert^2$\Comment{ Optimization}\Until{ converged}
\end{algorithmic}
\end{algorithm}

For the sampling, we may sample \(x_0\sim p_{\theta}(x_0)\) by the
following:

\begin{itemize}
\tightlist
\item
  Sample \(x_T\sim \mathcal{N}(\mathbf{0},\mathbf{I}).\)
\item
  Sample \(x_{t-1}\sim p_{\theta}(x_{t-1}\vert x_t)\) inductively for
  \(t=T,T-1,\cdots,1.\)
\end{itemize}

Recall that
\(p_{\theta}(x_{t-1}\vert x_t)\sim \mathcal{N}(\mu_{\theta}(x_t,t),\sigma_t \mathbf{I}),\)
where \[
\begin{aligned}
  \mu_{\theta} (x_t,t) = \frac{1}{\sqrt{\alpha_t}} \Bigl( 
    x_t - \frac{\beta_t}{\sqrt{1-\overline{\alpha}_t}} \mathtt{Net}_{\theta} (x_t,t)
    \Bigr).
\end{aligned}
\]

Therefore, our sampling algorithm is as follows:

\begin{algorithm}[H]
\caption{Sampling (DDPM)}
\label{alg-diffusion-model-sampling-shortly}
\begin{algorithmic}[1]
\State $x_T\sim \mathcal{N}(\mathbf{0},\mathbf{I})$\For{ $t=T,\cdots,1$}\If{ $t>1$}\State $z \sim \mathcal{N}(\mathbf{0},\mathbf{I})$\Else\State $z= \mathbf{0}$\EndIf\State $x_{t-1}=\frac{1}{\sqrt{\alpha_t}}\Big(x_t-\frac{1-\alpha_t}{\sqrt{1-\overline{\alpha}_t}}\mathtt{Net}_{\theta}(x_t,t)\Big)+\sigma_t z$\EndFor\Return $x_0$
\end{algorithmic}
\end{algorithm}

\subsection{DDIM}\label{sec-DDIM}

One of the major drawbacks of DDPM is the lengthy time required for data
generation, especially when compared to other generative AI methods. In
response to this issue, an improved version of DDPM, known as Denoising
Diffusion Implicit Models (DDIM), was introduced by Song et al.~(Song,
Meng, and Ermon (2022)). The primary innovation of DDIM is its ability
to significantly accelerate the data generation process. By refining the
underlying diffusion mechanism, DDIM reduces the number of required
diffusion steps without sacrificing the quality of the generated data.
This breakthrough makes DDIM a more practical and efficient alternative
for generative AI tasks, offering faster performance while maintaining
high-quality outputs.

Now we introduce the DDIM. The main reason why we can decompose \(L\) in
Equation~\ref{eq-decom-L} in DDPM is that we have the following
production of two densities:
\begin{equation}\phantomsection\label{eq-q_prod}{
\begin{aligned}
  p_{\theta}(x_{0:T}) &= p_{\theta}(x_T) \cdot \prod_{t=2}^T p_{\theta}(x_{t-1}\vert x_t) \cdot  p_{\theta}(x_0\vert x_1) , \cr 
  q(x_{1:T}\vert x_0) &= q(x_T\vert x_0) \cdot \prod_{t=2}^{T} q(x_{t-1} \vert x_{t}, x_0).
\end{aligned}
}\end{equation} DDIM consider a new forward process
\(\bigl( \lbrace X_0,X_1,\cdots,X_T\rbrace, \mathbf{Q}_{\sigma} \bigr),\)
where \(\mathbf{Q}_{\sigma}\) is some probability measure indexed by
\(\sigma\in [0,\infty)^T\). The forward process is not a Markov chain
but has the same conditional density of \(X_{t}\) given \(X_0=x_0\) for
each \(t\) as DDPM. Inspired by Equation~\ref{eq-q_prod}, DDIM directly
defines the joint density \[
\begin{aligned}
  q_{\sigma}(x_{0:T}) := q_{\sigma}(x_T\vert x_0) \cdot \prod_{t=2}^T q_{\sigma}(x_{t-1}\vert x_t, x_0) \cdot q(x_0),
\end{aligned}
\] where
\(q_{\sigma}(x_T\vert x_0):=\mathcal{N}(\sqrt{\overline{\alpha}_T}x_0,(1-\overline{\alpha}_T)\mathbf{I})\)
and \[
\begin{aligned}
  q_{\sigma} (x_{t-1}\vert x_t,x_0) := \mathcal{N}\biggl( \sqrt{\overline{\alpha}_{t-1}}x_0 + \sqrt{1-\overline{\alpha}_{t-1} - \sigma_t^2} \cdot \frac{x_t-\sqrt{\overline{\alpha}_t}x_0}{\sqrt{1-\overline{\alpha}_t}} , \sigma_t^2 \mathbf{I} \biggr), \quad t=2,\cdots, T.
\end{aligned}
\] Note that \(q_{\sigma}(x_{0:T})\) is a density since it is a product
of densities. This seems a little weird that the joint density of
\(q_{\sigma}(x_{0:T})\) is determined by some conditional density. In
fact,
\(\bigl(\lbrace X_0,X_1,\cdots,X_T \rbrace,\mathbf{Q}_{\sigma}\bigr)\)
is a process satisfying the following conditions:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Under \(\mathbf{Q}_{\sigma},\) \(X_0\) has the density \(q(x_0).\)
\item
  Conditioned on \(X_0=x_0,\) the process
  \(\Bigl( \lbrace X_T,X_{T-1},\cdots, X_2,X_1\rbrace\Big\vert_{X_0=x_0}, \mathbf{Q}_{\sigma} \Bigr)\)
  is a Markov chain with

  \begin{itemize}
  \tightlist
  \item
    the initial density
    \(q_{\sigma}(x_T\vert x_0)= \mathcal{N}(\sqrt{\overline{\alpha}_T}x_0,(1-\overline{\alpha}_T)\mathbf{I})\)
    and
  \item
    the transition density \[
     \begin{aligned}
       q_{\sigma} (x_{t-1}\vert x_t,x_0) = \mathcal{N}\biggl( \sqrt{\overline{\alpha}_{t-1}}x_0 + \sqrt{1-\overline{\alpha}_{t-1} - \sigma_t^2} \cdot \frac{x_t-\sqrt{\overline{\alpha}_t}x_0}{\sqrt{1-\overline{\alpha}_t}} , \sigma_t^2 \mathbf{I} \biggr), \quad t=2,\cdots, T.
     \end{aligned}
     \]
  \end{itemize}

  Note that if we write
  \(q_{\sigma}(x_{t-1}\vert x_t,x_0)=\mathcal{N} \bigl(f(x_t,x_0,t), \sigma_t^2 \mathbf{I}\bigr),\)
  then the process
  \(\Bigl( \lbrace X_T,X_{T-1},\cdots, X_2,X_1\rbrace\Big\vert_{X_0=x_0}, \mathbf{Q}_{\sigma} \Bigr)\)
  can be write as, conditioned on \(X_0=x_0,\) \[
  \begin{aligned}
    X_{t-1} = f(X_t,x_0,t) + \sigma_t \xi_t, \quad t=T,\cdots, 2,
  \end{aligned}
  \] where \(X_T,\xi_{T-1},\xi_{T-2},\cdots, \xi_{1}\) are independent
  under \(\mathbf{Q}_{\sigma}.\)
\end{enumerate}

For each \(\sigma\in [0,\infty)^T,\) we can show that for this joint
density \(q_{\sigma}(x_{0:T}),\) \[
\begin{aligned}
  q_{\sigma}(x_0) &= q(x_0), \cr
  q_{\sigma} (x_t \vert x_0) &= \mathcal{N} \bigl(\sqrt{\overline{\alpha}_t}x_0, (1-\overline{\alpha}_t)\mathbf{I}\bigr) = q(x_t\vert x_0) , \quad t=1,\cdots,T.
\end{aligned}
\] DDIM consider the backward process
\(\bigl( \lbrace X_T,X_{T-1},\cdots,X_1,X_0 \rbrace, \mathbf{P}_{\theta} \bigr)\)
as a Markov chain with the initial distribution
\(p_{\theta}({x_T})=\mathcal{N}(\mathbf{0},\mathbf{I})\) and the
transition density \[
\begin{aligned}
  p_{\theta}(x_0\vert x_1) &= \mathcal{N}( {\color{blue}{\widehat{x}_0(x_1,1)}}, \sigma_1^2 \mathbf{I} )  , \cr
  p_{\theta}(x_{t-1}\vert x_t) &= q_{\sigma}(x_{t-1}\vert x_t,{\color{blue}{\widehat{x}_0}}) \cr
  &= \mathcal{N}\biggl( \sqrt{\overline{\alpha}_{t-1}}{\color{blue}{\widehat{x}_0}} + \sqrt{1-\overline{\alpha}_{t-1} - \sigma_t^2} \cdot \frac{x_t-\sqrt{\overline{\alpha}_t}{\color{blue}{\widehat{x}_0}}}{\sqrt{1-\overline{\alpha}_t}} , \sigma_t^2 \mathbf{I} \biggr), \quad t=2,\cdots, T,
\end{aligned}
\] where \({\color{blue}{\widehat{x}_0}}=\widehat{x}_0(x_t,t)\)
satisfies \[
\begin{aligned}
  x_t = \sqrt{\overline{\alpha}_t}\cdot \widehat{x}_0 (x_t,t) + \sqrt{1-\overline{\alpha}_t} \cdot \mathtt{Net}_{\theta}(x_t,t), \quad x\in \mathbb R^n,\, t\in \mathbb N.
\end{aligned}
\] By the constructions of \(q_{\sigma},p_{\theta},\) we still have the
decomposition \[
\begin{aligned}
  &\mathbb E_{X_{0:T}\sim q_{\sigma}(x_{0:T})} \Bigl[ -\log \frac{p_{\theta}(X_{0:T})}{q_{\sigma}(X_{1:T}\vert X_0)} \Bigr] \cr  
  &= \underbrace{\mathbb E_{X_0\sim q_{\sigma}(x_0)} \biggl[ D_{\mathtt{KL}} \Bigl( \underline{q_{\sigma}(x_T \vert x_0)} \big\Vert \underline{p(x_T)} \Bigr) \Big\vert_{x_0=X_0} \biggr]}_{L_T} \cr 
  & \qquad + \sum_{t=2}^T 
  \underbrace{\mathbb E_{X_0,X_t\sim q_{\sigma}(x_0,x_{t})} \biggl[ 
    D_{\mathtt{KL}} \Bigl( 
            {\underline{\color{red}{q_{\sigma}(x_{t-1} \vert x_t,x_0)}}}
            \big\Vert 
            \underline{\color{blue}{p_{\theta}(x_{t-1}\vert x_t)} }
            \Bigr)\Big \vert_{x_0,x_t=X_0,X_t} 
    \biggr]}_{L_{t-1}}  \cr 
    & \qquad \qquad + \underbrace{\mathbb E_{X_0,X_1\sim q_{\sigma}(x_0,x_1)} \biggl[ 
      -\log {\color{blue}{p_{\theta}(x_0 \vert x_1)}} \Big\vert_{x_0,x_1=X_0,X_1}
      \biggr]}_{L_0}.
\end{aligned}
\] There are two special values for \(\sigma.\)

\begin{itemize}
\item
  The first one is \[
  \begin{aligned}
    \sigma_t = \sqrt{(1-\overline{\alpha}_{t-1})/(1-\overline{\alpha}_t)} \sqrt{ 1-\alpha_t }, \quad t = 1,\cdots, T.
  \end{aligned}
  \] Under this \(\sigma,\) the process
  \(\bigl(\lbrace X_0,X_1,\cdots,X_T \rbrace,\mathbf{Q}_{\sigma}\bigr)\)
  becomes a Markov chain, hence the DDIM becomes the original DDPM.
\item
  The second one is \(\sigma_t = 0\) for \(t=1,2,\cdots, T.\) In this
  case, the backward process
  \(\bigl(\lbrace X_T,X_{T-1},\cdots,X_0 \rbrace,\mathbf{P}_{\theta}\bigr)\)
  becomes deterministic when we condition on \(X_T = x_T.\) This greatly
  speeds up the sampling of diffusion models. In this case, we may write
  \[
  \begin{aligned}
    X_{t-1} = \sqrt{\overline{\alpha}_{t-1}} \widehat{X}_0 (X_t,t)  +  \sqrt{1-\overline{\alpha}_{t-1}} \cdot \mathtt{Net}_{\theta}(X_t,t), \quad t=T,T-1,\cdots, 1.
  \end{aligned}
  \]
\end{itemize}

\subsection{Conditional Diffusion Model}\label{sec-cdm}

Dhariwal and Nichol (2021)

\begin{itemize}
\item
  一般沒有限定條件的 diffusion
  model，我們無法去控制想生成的東西。這明顯無法滿足我們的需求。 比如說在
  mnist 之中，我們想要去控制生成 0\textasciitilde9 的是哪個數字。
  又比如說 celebA
  這資料集中，我們想要去生成的大頭像有什麼特徵（比如說是男是女，有無戴眼鏡）。
  所以自然而然會有所謂的 Conditional diffusion model。
\item
  我們先從簡單類別的說起，用 mnist 的數字來解釋。 我們現在有資料集
  \(X \times Y\) 的分佈 \[
  \begin{aligned}
    \widehat{q}(x_0,y), \quad x_0 \in \mathbb R^{w\times h}, \quad y\in \mathbb R^n,
  \end{aligned}
  \] where

  \begin{itemize}
  \tightlist
  \item
    \(X_0\) 是數字圖片;
  \item
    \(Y\) 是數字 label 在 \(\mathbb R^n\) 的 embed

    \begin{itemize}
    \tightlist
    \item
      That is, \(\mathbb R^n\) is the embed space of labels.
    \item
      For this example, \(0,1,\cdots, 9\) are
      \texttt{nn.Embedding(10,n)(torch.arange(10))}. （所以這裡 embed
      也是要可學習的）.
    \end{itemize}
  \end{itemize}
\item
  Given the label \(Y = y.\) We want to generate an image \(x_0\) which
  has the label \(y.\)
\item
  Assume that we already have \(\widehat{q}(y\vert x_0).\) That is, when
  we have \(x_0,\) we know the distribution of labels of \(x_0.\)
\item
  如果忽略掉 \(Y,\) 只看 \(X_0,\) 可視為之前的 unconditional diffusion
  model
\item
  We define \(q\) as before:

  \begin{itemize}
  \tightlist
  \item
    \(q(x_0)\): the distribution of \(X_0\) (無表達式);
  \item
    \(q(x_t\vert x_{t-1})= \mathcal{N}(\sqrt{\alpha_t}x_{t-1}, (1-\alpha_t)\mathbf{I}).\)
  \end{itemize}
\end{itemize}

\paragraph{Important}\label{important}

\begin{itemize}
\item
  同樣地我們令 \(\lbrace X_t \rbrace_{t=0}^T\) 為時間 \(t\)
  時的加噪圖片, 只是加噪方式是如下:

  \textbf{Define} the forward process of \((X_{0:T},Y)\) by the
  following:

  \begin{itemize}
  \tightlist
  \item
    \(\widehat{q}(x_0):= q(x_0)\) (無表達式) (eq 28).

    \begin{itemize}
    \tightlist
    \item
      So that we have
      \(\widehat{q}(x_0,y)=\underbrace{q(x_0)}_{\text{無表達式}} \cdot \underbrace{\widehat{q}(y\vert x_0)}_{\text{有表達式}}.\)
    \end{itemize}
  \item
    \(\widehat{q}(x_t\vert x_{t-1},y):= q(x_{t}\vert x_{t-1})\)
    (有表達式) (eq 30);
  \item
    \(\widehat{q}(x_{1:T}\vert x_0,y):= \prod_{t=1}^T \widehat{q}(x_t\vert x_{t-1},y)\)
    (eq 31).

    \begin{itemize}
    \tightlist
    \item
      Conditioned on \(Y=y,\) the forward process \(X_0,X_1,\cdots,X_T\)
      is a Markov chain with the transition density
      \(q(x_t\vert x_{t-1}).\)
    \end{itemize}
  \end{itemize}

  Note that \[
  \begin{aligned}
    \widehat{q}(x_{0:T},y)
    &= \widehat{q}(x_0,y) \cdot \widehat{q}(x_{1:T}\vert x_0,y), \cr 
    &= \widehat{q}(x_0,y) \cdot \prod_{t=1}^T \widehat{q}(x_t\vert x_{t-1},y).
  \end{aligned}
  \]
\item
  For this \(\widehat{q},\) we have

  \begin{itemize}
  \item
    \(\widehat{q}(x_{t}\vert x_{t-1})=\widehat{q}(x_{t}\vert x_{t-1},y)\)
    (eq 32\textasciitilde37) \(= q(x_t\vert x_{t-1})\) (eq 30);
  \item
    \(\widehat{q}(x_{1:T}\vert x_0)= q(x_{1:T}\vert x_0)\) (eq
    38\textasciitilde44);
  \item
    \(\widehat{q}(x_t)=q(x_t)\) (eq 45\textasciitilde50);
  \item
    \(\widehat{q}(x_{t-1}\vert x_{t}) = q(x_{t-1}\vert x_{t})\);
  \item
    (上面四點說明 \(\widehat{q}\) 在不考慮 label 時, 跟之前的 diffusion
    model \(q\) 分佈完全一樣);
  \item
    \(\widehat{q}(y\vert x_{t-1},x_{t}) = \widehat{q}(y\vert x_{t-1})\)
    (eq 51\textasciitilde54);
  \item
    \(\widehat{q}(x_{t-1}\vert x_{t},y) = \underbrace{q(x_{t-1}\vert x_{t})}_{\approx p_{\theta}(x_{t-1}\vert x_{t})} \cdot \underbrace{\widehat{q}(y\vert x_{t-1})}_{\approx p_{\phi}(y\vert x_{t-1})} \Big/ \underbrace{\widehat{q}(y\vert x_{t})}_{\text{constant}}\)
    (eq 55\textasciitilde61).

    \begin{itemize}
    \tightlist
    \item
      Note that \(p_{\phi}(y\vert x_t)\) 是 \(p_{\phi}(y\vert x_t,t)\)
      的縮寫.
    \item
      Note that
      \(p_{\theta}(x_{t-1}\vert x_{t}), p_{\phi}(y\vert x_{t-1})\) is
      our model.

      \begin{itemize}
      \tightlist
      \item
        這裡可以使用已經訓練好的 \(p_{\theta}\) (純粹DDPM的) 和 分類器.
      \end{itemize}
    \end{itemize}
  \item
    Define
    \(p_{\theta,\phi}(x_{t-1}\vert x_t,y) = \text{constant}\cdot  p_{\theta}(x_{t-1}\vert x_{t}) \cdot p_{\phi}(y\vert x_{t-1}).\)
    So when given the label \(y,\) we sample \(x_0\) (with label \(y\))
    by the following:

    \begin{itemize}
    \tightlist
    \item
      \textbf{For} \(t=T,T-1,\cdots,1,\)

      \begin{itemize}
      \tightlist
      \item
        Sample \(x_t\sim p_{\theta,\phi}(x_{t-1}\vert x_t,y)\)
      \end{itemize}
    \item
      \textbf{EndFor}
    \end{itemize}

    We organize the formula \(p_{\theta,\phi}(x_{t-1}\vert x_t,y).\)
    Consider \(x_t, y\) as two given constants. Using a Taylor expansion
    at \(x_{t-1}=\mu\) (some constant), we have \[
    \begin{aligned}
      \log p_{\phi}(y\vert x_{t-1}) 
      &\approx  \log p_{\phi}(y\vert x_{t-1})\Big\vert_{x_{t-1}=\mu} + (x_{t-1}-\mu) \nabla_{x_{t-1}} \log p_{\phi}(y\vert x_{t-1})\Big\vert_{x_{t-1}=\mu} \cr
      % &\approx  \log p_{\phi}(y\vert x_{t-1})\Big\vert_{x_{t-1}=\mu} + (x_{t-1}-\mu) \nabla_{x_{t}} \log p_{\phi}(y\vert x_{t})\Big\vert_{x_{t}=\mu} \cr  
      &= (x_{t-1}-\mu) \cdot 
    \end{aligned}
    \]
  \end{itemize}
\end{itemize}

\paragraph{Sampling (DDPM with
classifier)}\label{sampling-ddpm-with-classifier}

\begin{itemize}
\tightlist
\item
  \textbf{Given:} 訓練好的 \(p_{\theta}(x_{t-1}\vert x_t)\) (DDPM) 和
  分類器 \(p_{\phi}(y\vert x_{t-1}).\)
\item
  \textbf{Input:} A label \(y\) and a gradient scale \(s\in (1,\infty)\)
\item
  Sample \(x_T\sim \mathcal{N}(\mathbf{0},\mathbf{I}).\)
\item
  \textbf{For} \(t=T,T-1,\cdots,1\)

  \begin{itemize}
  \tightlist
  \item
    \(\mu,\Sigma \leftarrow \mu_{\theta}(x_t), \Sigma_{\theta}(x_t)\)
  \item
    Sample \(x_{t-1}\sim \mathcal{N}\bigl( \mu , \Sigma \bigr)\)

    \begin{itemize}
    \tightlist
    \item
      \textbf{Comment} Sample from unconditional diffusion model
    \end{itemize}
  \item
    \(x_{t-1}\leftarrow x_{t-1} + s \Sigma \nabla_{x_t} \log p_{\phi} (y\vert x_t)\)

    \begin{itemize}
    \item
      \textbf{Comment} 有點像是對
      \(p_{\theta,\phi}(x_{t-1}\vert x_t,y)\) 做 gradient ascent, 增加
      \(y\) 的 log-likelihood. 引導 \(x_{t-1}\) 向 label \(y\)
      的方向前進.
    \end{itemize}
  \end{itemize}
\item
  \textbf{EndFor}
\item
  \textbf{Return} \(x_0\)
\end{itemize}

\subsection{Predict Velocity}\label{predict-velocity}

We have two predictions in the following.

\begin{itemize}
\item
  The first is to predict the initial image \(X_0\) by giving \(X_t.\)
  We set \[
  \begin{aligned}
    \mu_{\theta}(x_t,t) 
    &= \mu_t \Bigl( x_t, \mathtt{Net}_{\theta}(x_t,t) \Bigr) \cr
    &= \frac{\sqrt{\alpha_t}(1-\overline{\alpha}_{t-1})}{1-\overline{\alpha}_t}x_t + \frac{\sqrt{\overline{\alpha}_{t-1}}\beta_t}{1-\overline{\alpha}_t} \cdot \mathtt{Net}_{\theta}(x_t,t) , \quad x_t \in \mathbb R^n,\, t=2, \cdots, T,
  \end{aligned}
  \] and then \[
  \begin{aligned}
    \Bigl\lVert \mu_t(x_t,x_0)- \mu_{\theta}(x_t,t) \Bigr\rVert 
    = \frac{\sqrt{\overline{\alpha}_{t-1}}\beta_t}{1-\overline{\alpha}_t} \Bigl\lVert  x_0 - \mathtt{Net}_{\theta}(x_t,t) \Bigr\rVert.
  \end{aligned}
  \]
\item
  The second is to predict the noise \(\overline{\varepsilon}_t\) by
  giving \(x_t,t.\) We set \[
  \begin{aligned}
    \mu_{\theta}(x_t,t)
    &= \widetilde{\mu}_t \Bigl( x_t, \mathtt{Net}_{\theta}(x_t,t) \Bigr)  \cr
    &= \frac{1}{\sqrt{\alpha_t}} \Bigl( 
      x_t - \frac{\beta_t}{\sqrt{1-\overline{\alpha}_t}} \cdot \mathtt{Net}_{\theta}(x_t,t)
    \Bigr) , \quad x_t \in \mathbb R^n,\, t=2,\cdots, T,
  \end{aligned}
  \] and then \[
  \begin{aligned}
    \Bigl\lVert \mu_t(x_t,x_0)- \mu_{\theta}(x_t,t) \Bigr\rVert =  \frac{\beta_t}{\sqrt{\alpha_t}\cdot \sqrt{1-\overline{\alpha}_t}} \Bigl\lVert \overline{\varepsilon}_t - \mathtt{Net}_{\theta}(x_t,t)  \Bigr\rVert.
  \end{aligned}
  \]
\end{itemize}

In the backward process, we predict the noise
\(\overline{\mathcal{E}}_t\) or the initial image \(X_0.\) There is
another prediction (prediction for the velocity, see TODO: pred\_v). For
simplicity, we set \[
\begin{aligned}
  a_t := \sqrt{\overline{\alpha}_t}, \quad b_t := \sqrt{1-\overline{\alpha}_t}.
\end{aligned}
\] Then we may rewrite \[
\begin{aligned}
  X_t = a_t X_0 + b_t \overline{\mathcal{E}}_t, \quad a_t^2+b_t^2 = 1.
\end{aligned}
\] Define the velocity, a random vector we want to predict, \[
\begin{aligned}
  V_t := -b_t X_0 + a_t \overline{\mathcal{E}}_t.
\end{aligned}
\] Then we have the following relations: \[
\begin{aligned}
  X_0 &= a_t X_t - b_t V_t , \cr  
  \overline{\mathcal{E}}_t &= b_t X_t + a_t V_t.
\end{aligned}
\]

Then our algorithms become

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Training

  \begin{itemize}
  \tightlist
  \item
    \(x_0\sim q(x_0)\)
  \item
    \(\overline{\varepsilon}_t \sim \mathcal{N}(\mathbf{0},\mathbf{I})\)
  \item
    \(x_t=a_t x_0 + b_t \overline{\varepsilon}_t\)
  \item
    \(v_t = -b_t x_0 + a_t \overline{\varepsilon}_t\)
  \item
    Loss is
    \(\bigl\lVert \texttt{Net}_{\theta} (x_t,t) - v_t \bigr\rVert^2\)
  \end{itemize}
\item
  Sampling

  \begin{itemize}
  \tightlist
  \item
    \(\widehat{v}=\texttt{Net}_{\theta}(x_t,t)\)
  \item
    \(\widehat{\varepsilon}=b_t x_t + a_t \widehat{v},\quad \widehat{x}_0=a_t x_t - b_t \widehat{v}\)
  \item
    \(\widehat{\mu}=\frac{1}{\sqrt{\alpha_t}}\Bigl( x_t- \frac{\beta_t}{b_t} \Bigr) \widehat{\varepsilon}\)
  \end{itemize}
\end{enumerate}

\section{Experiments}\label{experiments}

\section{Conclusion}\label{conclusion}

\newpage{}

\section*{References}\label{references}
\addcontentsline{toc}{section}{References}

\phantomsection\label{refs}
\begin{CSLReferences}{1}{0}
\bibitem[\citeproctext]{ref-ANDERSON1982313}
Anderson, Brian D. O. 1982. {``Reverse-Time Diffusion Equation
Models.''} \emph{Stochastic Processes and Their Applications} 12 (3):
313--26. \url{https://doi.org/10.1016/0304-4149(82)90051-5}.

\bibitem[\citeproctext]{ref-dhariwal2021diffusion}
Dhariwal, Prafulla, and Alex Nichol. 2021. {``Diffusion Models Beat GANs
on Image Synthesis.''} \url{https://arxiv.org/abs/2105.05233}.

\bibitem[\citeproctext]{ref-goodfellow2014generative}
Goodfellow, Ian J., Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David
Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014.
{``Generative Adversarial Networks.''}
\url{https://arxiv.org/abs/1406.2661}.

\bibitem[\citeproctext]{ref-SNR}
Hang, Tiankai, Shuyang Gu, Chen Li, Jianmin Bao, Dong Chen, Han Hu, Xin
Geng, and Baining Guo. 2023. {``Efficient Diffusion Training via Min-SNR
Weighting Strategy.''} In \emph{Proceedings of the IEEE/CVF
International Conference on Computer Vision (ICCV)}, 7441--51.

\bibitem[\citeproctext]{ref-ho2020denoising}
Ho, Jonathan, Ajay Jain, and Pieter Abbeel. 2020. {``Denoising Diffusion
Probabilistic Models.''} \emph{Advances in Neural Information Processing
Systems} 33: 6840--51.

\bibitem[\citeproctext]{ref-kingma2022autoencoding}
Kingma, Diederik P, and Max Welling. 2022. {``Auto-Encoding Variational
Bayes.''} \url{https://arxiv.org/abs/1312.6114}.

\bibitem[\citeproctext]{ref-pmlr-v37-sohl-dickstein15}
Sohl-Dickstein, Jascha, Eric Weiss, Niru Maheswaranathan, and Surya
Ganguli. 2015. {``Deep Unsupervised Learning Using Nonequilibrium
Thermodynamics.''} In \emph{Proceedings of the 32nd International
Conference on Machine Learning}, edited by Francis Bach and David Blei,
37:2256--65. Proceedings of Machine Learning Research. Lille, France:
PMLR. \url{https://proceedings.mlr.press/v37/sohl-dickstein15.html}.

\bibitem[\citeproctext]{ref-song2022denoising}
Song, Jiaming, Chenlin Meng, and Stefano Ermon. 2022. {``Denoising
Diffusion Implicit Models.''} \url{https://arxiv.org/abs/2010.02502}.

\end{CSLReferences}

\newpage{}

\setcounter{section}{0}
\renewcommand{\thesection}{\Alph{section}}
\setcounter{table}{0}
\renewcommand{\thetable}{A\arabic{table}}
\setcounter{figure}{0}
\renewcommand{\thefigure}{A\arabic{figure}}

\section{Appendix}\label{appendix}

\subsection{Markov property is equivalent to adding noise
independently}\label{sec-markov-equivalent}

Given the probability measure \(\mathbf{Q}\) such that

\begin{itemize}
\tightlist
\item
  \(q(x_0)\) is the mass (respect to \(\mathbf{Q}\)) of our image data,
  and
\item
  \(X_0,\mathcal{E}_1,\cdots,\mathcal{E}_T\) are independent under
  \(\mathbf{Q},\) and
\item
  \(\mathcal{E}_t\sim \mathcal{N}(\mathbf{0},\mathbf{I})\) under
  \(\mathbf{Q}\) for \(t=1,\cdots, T.\)
\end{itemize}

Under the assumptions above, we have the following properties under
\(\mathbf{Q}\):

\begin{itemize}
\item
  Under \(\mathbf{Q},\) if we set \[
  \begin{aligned}
    X_t = \sqrt{\overline{\alpha}_t}X_{0}+\sqrt{1-\overline{\alpha}_t}\cdot \overline{\mathcal{E}}_t,
  \end{aligned}
  \] then \(X_0,\) \(\overline{\mathcal{E}}_t\) are independent, and
  \(\overline{\mathcal{E}}_t\sim \mathcal{N}(\mathbf{0},\mathbf{I}).\)
  Note that this property says that
  \(q(x_T)\approx \mathcal{N}(\mathbf{\mathbf{0},\mathbf{I}})\) as \(T\)
  large.
\item
  Under \(\mathbf{Q},\) \(\lbrace X_0,X_1,\cdots,X_T\rbrace\) is a
  Markov chain with the transition density \[
  \begin{aligned}
    q(x_t\vert x_{t-1}) = \mathcal{N}(\sqrt{\alpha_t}x_{t-1},\beta_t \mathbf{I}).
  \end{aligned}
  \]
\end{itemize}

\begin{remark}
Note that the Markov property is equivalent to adding noise
independently. That is, if
\(\bigl( \lbrace X_t\rbrace_{t=0}^T, \mathbf{Q} \bigr)\) is a Markov
chain with the transition density \[
\begin{aligned}
  q(x_t\vert x_{t-1}) = \mathcal{N}(\sqrt{\alpha_t}x_{t-1},\beta_t \mathbf{I}).
\end{aligned}
\] and we set \[
\begin{aligned}
  X_t = \sqrt{\overline{\alpha}_t}X_{0}+\sqrt{1-\overline{\alpha}_t}\cdot \overline{\mathcal{E}}_t,
\end{aligned}
\] then

\begin{itemize}
\tightlist
\item
  \(X_0,\mathcal{E}_1,\cdots,\mathcal{E}_T\) are independent under
  \(\mathbf{Q},\) and
\item
  \(\mathcal{E}_t\sim \mathcal{N}(\mathbf{0},\mathbf{I})\) under
  \(\mathbf{Q}\) for \(t=1,\cdots, T.\)
\end{itemize}

\end{remark}

\subsection{\texorpdfstring{\(q(x_0) \approx p(x_0)\)}{q(x\_0) \textbackslash approx p(x\_0)}}\label{qx_0-approx-px_0}

Note that \[
\begin{aligned}
  q(x_{0:3}) 
  &= q(x_3\vert x_2) \cdot q(x_2\vert x_1) \cdot q(x_1\vert x_0) \cdot q(x_0) \cr 
  &= \frac{q(x_3)}{q(x_2)}q(x_2\vert x_3) \cdot \frac{q(x_2)}{q(x_1)}q(x_1\vert x_2)\cdot \frac{q(x_1)}{q(x_0)} q(x_0\vert x_1) \cdot q(x_0) \cr 
  &= q(x_0\vert x_1) \cdot q(x_1\vert x_2) \cdot q(x_2\vert x_3) \cdot \underbrace{q(x_3)}_{\approx \mathcal{N}(\mathbf{0},\mathbf{I})}
\end{aligned}
\] and \[
\begin{aligned}
  p(x_{0:3}) = q(x_0\vert x_1) \cdot q(x_1\vert x_2) \cdot q(x_2\vert x_3) \cdot \underbrace{p(x_3)}_{\mathcal{N}(\mathbf{0},\mathbf{I})}.
\end{aligned}
\] Then \[
\begin{aligned}
  q(x_0) = \int_{x_{1:3}} q(x_{0:3}) \, \mathrm{d}x_{0:3} \approx \int_{x_{1:3}} p(x_{1:3}) \, \mathrm{d}x_{0:3} = p(x_0).
\end{aligned}
\]

\subsection{SDE}\label{sde}

If \((X_t)_{t\in [0,1]}\) satisfies the SDE \[
\begin{aligned}
  \mathrm{d} X_t = \mu(X_t,t) \mathrm{d}t + \sigma(X_t,t) \mathrm{d}B_t,
\end{aligned}
\] where \(\mu(\cdot ,t):\mathbb R^n\longrightarrow \mathbb R^n\) and
\(\sigma(\cdot ,t): \mathbb R^n \longrightarrow \mathbb R^{n\times n}\)
and \((B_t)_{t\in [0,1]}\) is a standard \(n\)-dimensional Brownian
Motion. Let \(q(\cdot , t)\) be the density of \(X_t\) for each
\(t\in [0,1].\) We have the following results:

\begin{itemize}
\item
  For \(t\in [0,1],\) we define \[
  \begin{aligned}
    \overline{X}_t &:= X_{1-t}, \quad  &
    \overline{q}(\cdot , t) &:= q(\cdot , 1-t), \quad\cr 
    \overline{\mu}(\cdot , t) &:= \mu(\cdot , 1-t), \quad  &
    \overline{\sigma}(\cdot , t) &:= \sigma( \cdot , 1-t ).
  \end{aligned}
  \] Then by Anderson (1982), the \textbf{reverse process}
  \((\overline{X}_t)_{t\in [0,1]}\) satisfies
  \begin{equation}\phantomsection\label{eq-reverseSDE0}{
  \begin{aligned}
    \mathrm{d} \overline{X}_t 
    &= \Bigl( \underbrace{-\overline{\mu}(X_t,t) + 
      \overline{\sigma} \bigl( \overline{X}_t,t \bigr) \overline{\sigma} \bigl( \overline{X}_t,t \bigr)^{\mathtt{T}} \nabla_{x} \log \overline{q}\bigl( \overline{X}_t,t \bigr) 
      + \nabla_x  \overline{\sigma} \bigl( \overline{X}_t,t \bigr) \overline{\sigma} \bigl( \overline{X}_t,t \bigr)^{\mathtt{T}}}_{\text{drift coefficient}}
      \Bigr) \mathrm{d}t  \cr 
    & \qquad + \underbrace{\overline{\sigma}\bigl( \overline{X}_t,t \bigr)}_{\text{diffusion coefficient}} \mathrm{d}\overline{B}_t,
  \end{aligned}
  }\end{equation} where \((\overline{B}_t)_{t\in [0,1]}\) is a standard
  \(n\)-dimensional Brownian Motion.

  \begin{itemize}
  \item
    Note that the diffusion coefficient of the reverse process
    \(\bigl( \overline{X}_t \bigr)_{t\in [0,1]}\) has the same form as
    \((X_t)_{t\in [0,1]}.\) This explains why it is reasonable to assume
    that \(\Sigma_{\theta}(x,t)\) is independent of \(x\) in
    Equation~\ref{eq-Sig_the_indep_x}.
  \item
    If \(\sigma(\cdot ,t)=\sigma(t)\) is independent of \(x,\) then
    \(\nabla_x  \overline{\sigma} \bigl( \overline{X}_t,t \bigr) \overline{\sigma} \bigl( \overline{X}_t,t \bigr)^{\mathtt{T}}=0\)
    and the drift coefficient of Equation~\ref{eq-reverseSDE0} is the
    original average \(-\overline{\mu}(X_t,t)\) guided by the score
    function
    \(\nabla_{x} \log \overline{q}\bigl( \overline{X}_t,t \bigr).\)
  \end{itemize}
\item
  Consider a process \((\widetilde{X}_t)_{t\in[0,1]}\) satisfies the ODE
  \[
  \begin{aligned}
    \mathrm{d}\widetilde{X}_t 
    = \Bigl( \mu(\widetilde{X}_t, t) 
    - \frac{1}{2} \sigma(\widetilde{X}_t,t) \sigma(\widetilde{X}_t,t)^{\mathtt{T}} \nabla_{x} \log q(\widetilde{X}_t,t) 
    - \frac{1}{2} \nabla_x \sigma(\widetilde{X}_t,t) \sigma(\widetilde{X}_t,t)^{\mathtt{T}} \Bigr) \mathrm{d}t.
  \end{aligned}
  \] Then for each \(t\in [0,1],\) \(X_t\) and \(\widetilde{X}_t\) have
  the same distribution.
\end{itemize}

\subsection{\texorpdfstring{Seperate
\(L\)}{Seperate L}}\label{seperate-l}

\[
\begin{aligned}
  L :=
  \mathbb E_{X_{0:T}\sim q(x_{0:T})} \Bigl[ -\log \frac{p_{\theta}(X_{0:T})}{q(X_{1:T}\vert X_0)} \Bigr].
\end{aligned}
\] \[
\begin{aligned}
  p_{\theta}(x_{0:T}) &= p_{\theta}(x_T) \cdot \prod_{t=2}^T p_{\theta}(x_{t-1}\vert x_t) \cdot  p_{\theta}(x_0\vert x_1) , \cr 
  q(x_{1:T}\vert x_0) &= \prod_{t=2}^{T} q(x_t \vert x_{t-1}) \cdot q(x_1\vert x_0) \cr 
  &= \prod_{t=2}^{T} q(x_t \vert x_{t-1}, x_0) \cdot q(x_1\vert x_0) \cr 
  &= \prod_{t=2}^{T} \frac{q(x_{t-1} \vert x_{t}, x_0) q(x_t\vert x_0) }{q(x_{t-1}\vert x_0)} \cdot q(x_1\vert x_0) \cr 
  &= q(x_T\vert x_0) \cdot \prod_{t=2}^{T} q(x_{t-1} \vert x_{t}, x_0)
\end{aligned}
\]



\end{document}
